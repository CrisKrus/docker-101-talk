# Docker 101

Guion para la presentaci칩n, todo est치 en https://www.cristiansuarez.dev/tags/docker

## Docker

Preguntar que esperan de la charla.

## Presentaci칩n

Mostrar las redes sociales que tengo y el QR para ver como de receptivos est치n a hacer tomar acci칩n.
Agradecer a los organizadores.

## 쯈ue es Docker?

Docker es la forma de tener una misma configuraci칩n de un proyecto independientemente de la m치quina o el sistema en el que te encuentres, siempre que tenga Docker instalado. Facilitando as칤 los despliegues y desarrollos de aplicaciones.

Adem치s de esto con Docker podr치s trabajar y jugar con distintas herramientas y tecnolog칤as sin llenar de paquetes que no te interesan en tu m치quina.

Quiero dejar claro que Docker no es una m치quina virtual, aunque de primeras puede parecerse bastante cuando veamos como funciona realmente comprobaremos que no se parece en nada. De primeras puedes pensarlo de esta forma, te har치 m치s f치cil entender el resto de conceptos, pero quiero dejar claro que **no es una m치quina virtual**

Como podemos ver en la imagen siguiente una m치quina virtual necesita tener un sistema operativo desde cero sobre el de nuestra m치quina *host*. Y luego, encima de este nuevo sistema tendremos las librer칤as necesarias y las aplicaciones que queremos probar.

En cambio, Docker comparte el mismo n칰cleo del sistema y aislar las librer칤as que queremos usar dentro del contenedor. Es decir, en el fondo, Docker se est치 ejecutando en tu m치quina, no en un sistema nuevo, pero aislar todos estos procesos y paquetes en una zona privada a la que nadie puede acceder (contenedor). Explicar칠 en otro post con m치s detalle.

## Conceptos

Antes de empezar necesitamos tener una serie de conceptos claros que nombraremos bastante a menudo. Estos son **imagen**, **contenedor** y **volumen**. Estas palabras las usaremos con frecuencia, ya que son la base de Docker.

### Imagen

Una **imagen** es una configuraci칩n para un contenedor, podemos hacer el s칤mil cuando creamos una clase para instanciar un objeto en programaci칩n. Creamos un molde con cierta configuraci칩n y funciones en su interior que podemos instanciar (crear) tantas veces como queramos en varios objetos y siempre ser치 de la misma forma.

Una imagen de Docker ser칤a nuestra clase en programaci칩n. Para configurar esta imagen como si de un fichero de programaci칩n se tratase Docker dispone de los **Dockerfile**, los cuales explicaremos m치s adelante. En ellos pondremos todos los datos que necesitamos para que funcione correctamente como las variables de entorno, comandos que ejecuta, etc.

### Contenedor

Siguiendo con el s칤mil anterior de la clase de programaci칩n y el objeto, un **contenedor** ser칤a una instancia de la clase que hemos creado. Es decir, creamos una instancia que tiene toda la configuraci칩n que y funciones que le hemos indicado. Podremos crear tantas como queramos.

Con esta clase ya definida da igual en que parte de nuestra aplicaci칩n la usemos siempre partir치 de la misma base. De forma que siempre podremos trabajar con ella partiendo del mismo punto.

Podemos crear tantos contenedores como nos sea necesario gestion치ndolos a nuestro gusto. Con esto quiero decir que un contenedor lo podemos crear, eliminar, parar, volver a arrancarlo, conectarnos a 칠l, dejarlo en segundo plano, exponer los puertos que nos interesen, etc. Iremos viendo como hacer cuando llegue el momento.

### Volumen

Adem치s, cada contenedor tiene asociado con 칠l un **volumen**. Los vol칰menes son donde cada contenedor guarda la informaci칩n que tiene en su interior como si de un "disco duro" propio se tratase.

Estos vol칰menes se encuentran en nuestro sistema y no dejan de ser carpetas que podemos ver. Este punto es importante tenerlo claro porque puede parecer "magia" c칩mo y d칩nde guarda la informaci칩n los contenedores, ya que no est치 a simple vista en el sistema y solo la vemos dentro del propio contenedor.

Y digo que es importante tenerlo en cuenta porque es normal en alg칰n momento hacerse la pregunta: 쯉e pierde la informaci칩n cuando apago el contenedor?

La respuesta corta es no, la informaci칩n no se pierde, como he dicho est치 en nuestro sistema en alg칰n punto. La respuesta larga es que si paramos un contenedor la siguiente vez que lo arranquemos seguir치 con todos los mismos datos en su interior tal cual lo hab칤amos dejado.

Dado que como cada una de estas tres partes (imagen, contenedor, volumen) son **independientes** entre s칤, una vez eliminamos un contenedor el volumen sigue existiendo en nuestro sistema, durante un tiempo.

## 쮺omo funciona Docker?

nos basta con abrir nuestra terminal y ejecutar este comando `docker run -it ubuntu`. Cuando se ejecute esta instrucci칩n estaremos dentro de una terminal nativa de ubuntu y tendremos una m치quina linux lista para trabajar desde la consola sin problemas.

Dentro de esta consola podremos ejecutar comandos como `apt update` `apt install wget` o lo que queramos. Todo lo que hagamos se mantendr치 dentro de nuestro contenedor. Cuando queramos salir tendremos que ejecutar `exit` y volveremos a estar en nuestra m치quina *host*.

Y te preguntar치s <<*쯖칩mo es todo esto posible? 쮺칩mo puedo tan r치pidamente trabajar con una m치quina linux sin miedos a contaminar mi m치quina local?*>> Todo esto es posible gracias a los *[namespaces](https://en.wikipedia.org/wiki/Linux_namespaces)* y los *[cgroups](https://en.wikipedia.org/wiki/Cgroups)*. Con estas dos tecnolog칤as podemos lograr que los contenedores consuman tantos recursos como nosotros le digamos (*[cgroups](https://en.wikipedia.org/wiki/Cgroups)*) y vean tanto como les correspondan (*[namespaces](https://en.wikipedia.org/wiki/Linux_namespaces)*).

Estas tecnolog칤as no son para nada nuevas han existido en los sistemas *unix* desde hace a침os. En el caso de los *[namespaces](https://en.wikipedia.org/wiki/Linux_namespaces)* desde el 2002 y los *[cgroups](https://en.wikipedia.org/wiki/Cgroups)* en el a침o 2007 fue su primera versi칩n estable. Con esto quiero decir, que es una tecnolog칤a estable de la cual podemos confiar el correcto funcionamiento, no es la 칰ltima moda que han sacado y est치n en su primera versi칩n prematura.

### Comprobar que no es una m치quina virtual

Para ver que realmente estos procesos que ejecutamos dentro de nuestro contenedor est치n en nuestra m치quina *host* podemos hacer un `sleep` en nuestro Docker de Ubuntu y, comprobar como se est치 ejecutando en nuestra m치quina local. Para ello iniciamos en un terminal un contenedor de Ubuntu y dentro de 칠l ejecutas `sleep` de 30 segundos, esto congelar치 la terminal durante 30 segundos.

```cmd
docker run -it --rm ubuntu
sleep 30

```

Mientras este `sleep` siga en funcionamiento, en otra terminal en nuestro equipo donde hemos arrancado el contenedor hacemos lo siguiente `ps -ejH` y buscamos entre toda la salida que obtenemos el proceso del contenedor que debe de estar como proceso hijo de docker. El resultado debe ser algo similar a lo siguiente.

```cmd
ps -ejH

# [...]
 3358  3358  3358 ?        00:00:09   dockerd
 3793  3793  3793 ?        00:00:14     docker-containe
 9967  9967  3793 ?        00:00:00       docker-containe
 9991  9991  9991 pts/0    00:00:00         bash
10776 10776  9991 pts/0    00:00:00           sleep
# [...]

```

Como hemos podido ver los comandos del contenedor est치n siendo ejecutados en nuestra m치quina pero con la ayuda de los *[namespaces](https://en.wikipedia.org/wiki/Linux_namespaces)* docker no nos da visi칩n de los mismos y desde dentro del contenedor no podemos ver nada de lo que ocurre en la m치quina host.

## Empezar a trabajar

### Instalaci칩n

Para comenzar basta con instalar Docker en nuestra m치quina. Dependiendo de nuestro sistema operativo tendremos que seguir unos pasos u otros. La [documentaci칩n oficial de Docker](https://docs.docker.com/install/#supported-platforms) es muy buena y nos har치 de gu칤a en este proceso.

El caso de Windows es un poco especial, tienes que tener en cuenta que no puedes al mismo tiempo usar las m치quinas virtuales y Docker porque da problemas con el Hyper-V. No estoy al d칤a con este tema, uso Ubuntu, pero he escuchado hablar mucho sobre este problema a mis compa침eros. Existen otra casu칤stica d칩nde Docker no puede acceder al disco duro de la m치quina y tienes que ir a la configuraci칩n de *Docker Desktop* para compartir el disco duro de la m치quina.

## Dockerfile

## Organizaci칩n en capas

Como veremos m치s adelante en nuestros *Dockerfile* cuando configuramos nuestra imagen ejecutamos ciertos comandos y cada comando `RUN`, `COPY` o `ADD` es considerado una capa. Con cada nueva instrucci칩n de este conjunto mencionado tenemos una nueva capa que se pone sobre la anterior. Cuando nosotros creamos una imagen basada en `Node`, por ejemplo, esta imagen que creamos est치 basada en la capa de node que viene de [DockerHub](https://hub.docker.com/) de node. Y, sobre de ella, nosotros decidimos que m치s ponerle. Como puede ser nuestros ficheros fuentes, instalar nuestras dependencias, etc.

Lo bueno de que funcione de esta forma es que la primera vez que creamos la imagen tardar치 un poco en instalar todas las dependencias de nuestro proyecto y ejecutar todos los comandos que le hemos indicado. Pero, una vez esto por primera vez, Docker guarda en cach칠 las capas y autom치ticamente comprobar치 que si la capa que vamos a crear es la misma que ya ten칤amos antes y la estamos creando sobre la misma que estaba antes el resultado ser치 el mismo de siempre. Y Docker usar치 la misma que tiene guardada ahorrando tiempo en la creaci칩n de la nueva imagen.

## Imagen 1

Como vimos en [como crear mi primer contenedor](https://criskrus.com/2021/02/c칩mo-crear-mi-primer-contenedor/) podemos partir de una imagen creada de la siguiente forma.

```docker
# Dockerfile
FROM node

WORKDIR /app

COPY . /app

RUN npm install

EXPOSE 3000

CMD node index.js
```

El problema que presenta esta primera versi칩n es que dado el funcionamiento en capas con el que trabaja Docker esta imagen cada vez que hagamos un cambio en el c칩digo fuente instalar치 de nuevo todas las dependencias del proyecto. Dado que las dependencias no es algo que cambie con frecuencia nos interesa que al construir la imagen estas capas se usen desde el cach칠. Para ello podemos hacer la siguiente modificaci칩n.

```docker
FROM node

WORKDIR /app

COPY ./package.json ./package.json
COPY ./package-lock.json ./package-lock.json

RUN npm install

COPY ./src ./src

CMD node index.js

```

De esta forma la primera mitad del fichero `Dockerfile` hasta `RUN npm install` ser치 usado desde cach칠, ya que no cambia cuando hacemos nuevos desarrollos en nuestra aplicaci칩n. Como puede ser: a침adir un nuevo *endpoint.*

## Agrupar capas

Otra opci칩n muy com칰n cuando trabajamos con im치genes que parten de un sistema linux, por ejemplo, y queremos instalar ciertas dependencias es agrupar en una misma capa toda la instalaci칩n de paquetes. Esta idea est치 dentro de la documentaci칩n de [buenas pr치cticas](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#minimize-the-number-of-layers)

```docker
FROM ubuntu

RUN apt-get update && apt-get install -y \
  bzr \
  cvs \
  git \
  mercurial \
  node

WORKDIR /app
COPY ./src ./src

CMD node index.js
```

## *Multi stage building*

Otra opci칩n com칰n si queremos evitar tener dependencias en el despliegue las cuales son necesarias en la construcci칩n de nuestra aplicaci칩n podemos usar *multi stage build* (construcci칩n de im치genes multi-estado)

Esta t칠cnica tambi칠n se encuentra dentro del manual de [buenas pr치cticas](https://docs.docker.com/develop/develop-images/dockerfile_best-practices/#use-multi-stage-builds) de Docker. Con ella podemos crear varias im치genes en un solo fichero `Dockerfile` las cuales construyen parte de nuestra aplicaci칩n y copiar en la imagen final solamente los ficheros que necesitamos para funcionar.

En este caso partimos de una imagen de node a la que le damos el nombre de `builder`, instalamos las dependencias y construimos la aplicaci칩n. Esta aplicaci칩n queda guardada en el directorio `/build` dentro de la primera imagen. A continuaci칩n, creamos una nueva imagen y copiamos solo la parte que hemos construido necesaria para que nuestra app funcione al p칰blico y la arrancamos.

```docker
FROM node:10-alpine as builder

WORKDIR /app

COPY ./package.json ./package.json

RUN npm install

COPY ./src /app/src

RUN npm run build

FROM node:10-alpine

WORKDIR /app

COPY --from=builder /app/build/index.js ./index.js
COPY --from=builder /app/node_modules ./node_modules/

EXPOSE 8080

CMD node ./index.js
```

Con esta forma de construir im치genes docker nos ahorramos en la imagen final todos los datos y ficheros necesarios en la parte de construcci칩n. Esto hace que la imagen final sea menos pesada al tener menos informaci칩n.

## Comandos 칰tiles

En el CLI de docker existen muchas opciones, aqu칤 te dejo las que m치s suelo usar explicadas.

### `docker container run`

- `-d IMAGE` segundo plano
- `-i IMAGE` mantiene el input abierto (interactivo)
- `-t IMAGE` asigna un pseudo terminal. Estas dos 칰ltimas las suelo usar juntas casi siempre `-it` de esta forma (si la imagen lo permite) al arrancar se me queda una terminal abierta esperando ser usada desde dentro del contenedor.
- `-p 8000:5000 IMAGE` mapear el puerto para poder acceder. El 8000 mi m치quina se asigna al 5000 del contenedor
- `--rm IMAGE` elimina el contenedor al pararlo
- `-e MY_VARIABLE=foo IMAGE` al crear el contenedor establece la variable de entorno `MY_VARIABLE` con el valor `foo`

### `docker container`

- `ls -a` muestra todos los contenedores equivalente a `docker ps -a`
- `ls -q` lista los contenedores arrancados y solo muestra los ID equivalente a `docker ps -q`
- `exec CONTAINER COMMAND`, ejecuta dentro del contenedor en comando. Uno bastante sencillo ser칤a `docker exec -it ubuntu bash`
- `inspect CONTAINER`, muestra las propiedades el contenedor

### Limpiar Docker

Este apartado lo considero bastante importante porque de primeras puede parecer que Docker no genera archivos pero despu칠s de un tiempo trabajando con 칠l puedes tener en tu disco duro varios GB de vol칰menes sin usar. Conviene limpiar de vez en cuando.

- `docker container prune` elimina todos los contenedores parados
- `docker container rm CONTAINER` elimina el contenedor
- `docker container rm -v CONTAINER` elimina el contenedor y el volumen asociado
- `docker system prune --volumes` elimina todas las im치genes, contenedores y sus vol칰menes asociados.

## Conectar con IDE

Si eres de esas personas que no le gusta mucho trabajar desde el terminal o, simplemente tienes un d칤a en el que no te apetece escribir mucho, est치s de enhorabuena. Existen varias extensiones tanto para Visual Studio Code como intellij con las que podr치s gestionar docker, sus contenedores y mucho m치s.

## Visual Studio Code

Para este editor existen dos extensiones que har치n t칰 d칤a a d칤a con Docker mucho m치s c칩modo. La primera de ellas tiene pr치cticamente todo lo que necesitas: auto completado, crear im치genes con tan solo hacer click derecho en un dockerfile y decirle que haga el build y la parte que m치s me gusta un panel d칩nde puedes gestionar todo, TODO 游

![00-vscode.png](00-vscode.png)

Este panel se abre cuando pulsamos sobre la extension y podremos ver todos nuestros contenedores arrancados o parados. Las im치genes que tenemos localmente y sus diferentes etiquetas, vol칰menes, redes y lo que m치s me gusta podremos hacer limpieza de manera c칩moda y visual.

Y esto es solo lo que destaco de esta extensi칩n para Docker, si quieres saber m치s no dudes en consultar su documentaci칩n

[Docker - Visual Studio Marketplace](https://marketplace.visualstudio.com/items?itemName=ms-azuretools.vscode-docker)

### Conectarme a un contenedor

Si a esta primera extensi칩n le sumamos la que te voy a presentar a continuaci칩n podr치s salir de m치s de un apuro.

En ocasiones me ha pasado que estoy desarrollando y dentro de un contenedor el c칩digo no funciona como yo quiero y no tengo logs o necesito revisar si el c칩digo est치 tal cual yo espero. Esto lo puedo hacer desde consola, accediendo a los ficheros por terminal pero, porque no hacerlo con un editor 游땔

Con esta extension podemos ir a nuestro apartado de contenedores, dar click derecho y seleccionar "Attach Visual Studio Code". Despu칠s de unos segundos tendremos un editor el cual est치 conectado directamente al contenedor. Con 칠l podremos acceder y modificar ficheros dentro del mismo adem치s de, tener tantas terminales como queramos sin problema alguno.

[Remote - Containers - Visual Studio Marketplace](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers)

## Intellij

Si en tu caso usas el Intellij tengo buenas y no tan buenas noticias para ti. Existe la posibilidad de hacer esto mismo desde nuestro Intellij IDEA. Podemos gestionar nuestros contenedores e im치genes de manera visual y c칩moda, ver un resumen de cada contenedor, que puertos expone, abrir un terminal asociado con el mismo, etc. Pero, no podremos abrir un IDE asociado al contenedor como hemos visto hace un momento.

Todo ello desde la pesta침a de "servicios"

![01-intellij.png](01-intellij.png)

Y ahora es cuando te cuento la parte no tan buena... esta funcionalidad a d칤a de hoy solo est치 disponible en la versi칩n ultimate de este editor. As칤 que tendr치s que tener una licencia para poder hacer uso de ella 游뗷

## Preguntas

## Referencias

## Despedida

## BONUS, Persistencia

He escuchado varias veces decir que alguien no usa Docker porque al borrar el contenedor o al parar una base de datos toda la informaci칩n se perder치 en el olvido pero, nada m치s lejos de la realidad. Docker persiste la informaci칩n en nuestro sistema no lo crea y lo mantiene en un limbo virtual 游놑

Con esto quiero decir que cuando creamos un contenedor de Docker autom치ticamente, si no se lo indicamos, nos crear치 un directorio en nuestro sistema para guardar toda la informaci칩n que se encuentre dentro del mismo. La clave est치 en que nosotros podemos definir d칩nde queremos que haga este mapeo, incluso decirle que directorio concreto queremos que mapee dentro del contenedor. Esto se hace con los **vol칰menes**

Por ejemplo, si partimos de nuestra ***fake-api*** que hemos creado anteriormente en la cual primero copiamos nuestro c칩digo en el momento de la creaci칩n de la imagen con la sentencia `COPY . /app` dentro de nuestro archivo de configuraci칩n Dockerfile.

En el momento de la creaci칩n de la imagen no tenemos que hacer nada especial, ejecutaremos la sentencia igual que hasta ahora

```bash
docker build -t criskrus/fake-api .
```

La diferencia viene cuando creamos el contenedor. En este caso tendremos que indicar al contenedor que directorio tenemos que mapear. A nosotros para este ejemplo nos interesa que nuestro c칩digo fuente el cual modificamos en la m치quina anfitriona se modifique autom치ticamente en el contenedor para mostrar los cambios. Esto es de bastante utilidad cuando estamos en fases de desarrollo.

Para hacer esto tendremos que a침adir una nueva opci칩n en el comando de creaci칩n indicando que el directorio actual d칩nde est치 todo nuestro c칩digo corresponde con el c칩digo que se ejecuta dentro del contenedor. Esto se hace de la siguiente forma `-v $(pwd):/app`, con esta opci칩n decimos que el directorio actual se mapee al directorio `/app` del contenedor. Tenemos que usar el comando `pwd` porque tenemos que indicar la ruta absoluta.

Por lo tanto el nuevo comando con el que crearemos el contenedor queda de la siguiente forma.

```bash
docker run --rm -it  -p 8080:8080 -v $(pwd):/app criskrus/fake-api
```

Ahora, sin parar el contenedor, podemos hacer modificaciones en el c칩digo y veremos como se actualiza de manera autom치tica en el contenedor. Como tenemos instalado `nodemon` esta actualizaci칩n del servidor ocurrir치 autom치ticamente al actualizar el c칩digo sin necesidad de actualizar o hacer nada en nuestro contenedor.

Con esto podremos persistir y mantener en nuestra m치quina local lo que ocurra en el contenedor y nos interese mantener: configuraci칩n, logs, copias de seguridad de una base de datos, etc